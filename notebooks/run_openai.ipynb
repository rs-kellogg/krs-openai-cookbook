{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (1.51.1)\n",
      "Requirement already satisfied: python-docx in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (1.1.2)\n",
      "Requirement already satisfied: pandas in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/williamthompson/micromamba/envs/llm-env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai python-docx pandas python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from docx import Document\n",
    "import openai\n",
    "import docx\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def chat_complete(client, text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You are an annotator of transcripts. I want you to rate on a scale of 1-7 how tight being 7 or loose being 1 individuals are describing going about household and childcare tasks. You must return you result in JSON format, for example:\\n\\n{ eval: { 'tightness': 4,  'sentiment: 1 }\\n                    \\nHere's a definition and some examples: \\n                    \\nLoose= they decide to accomplish the household and childcare tasks depending on their schedules and when they have time. If someone observes that a particular task needs to get done, one of them will do it. This tends to be more ad hoc and with little planning or discussion. For example, One person describes a loose approach like this: \\\"We do not do a formal breakup of how we do things. My partner and I do a lot of things ad hoc. A lot of it is divide and conquer… it's like … I have to go take this one here, can you take this one here?\\\". Another person describes a loose approach like this: \\\"It just kind of fell into place. We really didn't talk about it just kind of happened.\\\" \\n\\n{'tightness': 1}\\n                    \\nTight= they decide to accomplish household and childcare tasks according to a predetermined and explicit schedule. The schedule outlines exactly who is responsible for each task, when it is being accomplished during the day/week, and where it will occur. For example, one person describes a tight approach like this: “On Tuesdays and Thursdays when I'm making dinner and picking my son up, my partner just works until dinner, around 6:00. The other two days, Monday and Wednesday, my partner picks my son up, so my partner gets off around 5:00 … and then makes dinner.” Another person describes a tight approach like this: \\\"I am responsible more for childcare tasks and my partner is more responsible for doing stuff around the house.\\\" Some terms that indicate tight are \\\"usually\\\" and \\\"always\\\". \\n\\n{'tightness': 7}\\n\\nAlso I want you to give me the sentiment of the transcript overall. Respond as follows: \\n\\n{ eval: { 'tightness': 1-7,  'sentiment: -1-1}\\n\\nTranscript: \"\n",
    "                }\n",
    "            ]\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": text\n",
    "                }\n",
    "            ]\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        response_format={\n",
    "            \"type\": \"json_object\"\n",
    "        }\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1.docx\n",
      "2_1.docx\n",
      "3_1.docx\n"
     ]
    }
   ],
   "source": [
    "file_list = list(Path(\"./data\").glob(\"*.docx\"))\n",
    "file_list.sort()\n",
    "response_dict = dict()\n",
    "for file in file_list:\n",
    "    text = extract_text_from_docx(file)\n",
    "    print(file.name)\n",
    "    response_dict[file.name] = chat_complete(client, text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval': {'tightness': 2, 'sentiment': 1}}\n",
      "{'eval': {'tightness': 2, 'sentiment': 0}}\n",
      "{'eval': {'tightness': 2, 'sentiment': 0}}\n",
      "defaultdict(<class 'list'>, {'file': ['1_1.docx', '2_1.docx', '3_1.docx'], 'tightness': [2, 2, 2], 'sentiment': [1, 0, 0]})\n",
      "       file  tightness  sentiment\n",
      "0  1_1.docx          2          1\n",
      "1  2_1.docx          2          0\n",
      "2  3_1.docx          2          0\n"
     ]
    }
   ],
   "source": [
    "data_dict = defaultdict(list)\n",
    "for key, value in response_dict.items():\n",
    "    response_vals = json.loads(value)\n",
    "    print(response_vals)\n",
    "    data_dict['file'].append(key)\n",
    "    data_dict['tightness'].append(response_vals['eval']['tightness'])\n",
    "    data_dict['sentiment'].append(response_vals['eval']['sentiment'])\n",
    "\n",
    "print(data_dict)\n",
    "df = pd.DataFrame(data_dict)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
